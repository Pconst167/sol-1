From: David Throop <LRC.Throop@UTEXAS-20.ARPA>
Subject: Humor - Excuse Generation


TOWARDS THE AUTOMATIC GENERATION OF EXCUSES
by David Throop

The Great and Pressing Need for Excuses.
  There is a huge need in industry for excuses.  A recent  marketing survey
shows that the biggest need in air transport is not for a service to get it
there overnight, but for one that takes the blame for it being three weeks
late.  Every time there is a dockworkers' strike anywhere in the world, titans
of commerce who are completely unaffected get on the phone.  They then explain
to all their customers that every order that is overdue is sitting on that
dock, and that they couldn't help it.  Then they grin.  Because they've got a
good excuse.  And even the smallest industrial project needs a raft of
excuses by the time it finishes.
  Computers have already helped with this need.  Many problems that used to be
blamed on the postal service, on the railroads and on telegraph operators are
now routinely blamed on computers.  "Your check is in the mail" has now been
supplemented by "Our computer has been down, and we'll send you your money as
soon as the repairman fixes it."  Whenever a bridge collapses, specialized
teams of system analysts are called in, in order to quickly blame the whole
mess on a computer.
  But computers can do more than this.  Computers have a place to play in the
generation of excuses; actually coming up with the lies and evasions that keep
our economy running.

The Structure of Excuses
  There is a great size range in excuses.  Many small excuses can be generated
without any AI or other advanced techniques.  And there will always be some
really big FUBARS that will need humans to come up with appropriate excuses.
But in between there is the somewhat stereotyped snafu that can be framed in
some structure and has different excuse elements as slots.  These are the
half-assed excuses, the most fruitful field for knowledge engineering.

Where It Came From
  It has been noted repeatedly in work on computer vision that a subject often
does not have all of the necessary information to justify an observation, but
that he makes it anyway and supplies some "excuse" to explain why some
features are missing.  The classic illustration of this problem is in
envisioning a chair: the subject may only be able to see three of the legs
but assumes a 4-legged chair.  Indeed, Dr. Minsky presented such a chair at the
AAAI in August.
  We interview the chair itself after the lecture, and asked it why it came
with only three legs.  The resulting string of excuses was impressive, and
more robust than one might expect from a broken piece of furniture.
  These included:
      "I'm not registered with the local chairs' union, so they'd only let me
        up on stage if I took off one of my legs.
      "Accounting cut my travel allowance by 18%, so I had to leave my leg
        back in California.
      "This is just a demo chair that we put together for the conference.  We
        have a programming team on the West coast that will have implemented
        another leg by October.
      "My secretary talked to somebody on the program committee who assured
        her that I wouldn't have to bring my own legs, and that there would be
        plenty of legs here in Austin.  Then I go here and found they were
        overbooked.
      "I felt that three legs was adequate to demonstrate the soundness of the
        general leg concept, and actually implementing a fourth leg would have
        been superfluous."

  This underlined a central observation: making excuses is critical to
perception, and is central to intelligence.  I mean, think about.  Sounding
intelligent involves making gross generalizations & venting primitive
prejudices and then making plausible excuses for them when they collide with
reality.  Any imaginable robot that understands the consequences of its action
will want to weasel out of them.

     The 3 legged chair problem yielded a high number of palatable excuses.
This toy problem shows the feasibility of generating large numbers of
industrial-strength excuses.  This goal would free humans from having to
justify their actions, leaving them more time to spend on screwing things
up.  That, after all, seems to be what they are best at.

How It Works
  A user makes request via SNIVEL (Stop-Nagging,-I'm-Verifying-an-Excuse
Language), a user-friendly system that nods, clucks sympatheticly, encourages
the user to vent his hostility & frustration, and has a large supply of
sympathetic stock answers for lame excuses:
  "You poor dear, I know you were trying as hard as you could.
  "Well, you can't be blamed for trusting them.
  "I can certainly see how you couldn't get your regular work done after an
     emotional shock like that."

  The program then begins to formulate an excuse appropriate to the problem.
Many problems can be recognized trivially and have stock excuses.  These can
be stored in a hash table and supplied without any search at all:
  "The dog vomited on it, so I threw it out.
  "It's in the mail.
  "I thought you LIKED it when I did that.
  "Six debates would probably bore the public.
  "I have a headache tonight.
  "I trusted in the advice of my accountant/lawyer/broker/good-time mama."

  If the problem is more complex, SNIVEL enters into a dialog with the user.
Even if he wants to take responsiblity for his share of the problem, SNIVEL
solicits the user, getting him to blame other people and explain why it wan't
REALLY his fault.  A report may be late getting to a client, for instance; it
may ask what last minute changes the client had requested, and what kinds of
problems the user had with a typing pool.  SNIVEL shares records with the
personnel file, so that it can quickly provide a list of co-workers' absences
that problably slowed the whole process down.  It has a parsing alogrithm that
takes the original work order and comes with hundreds of different parses for
each sentence, demonstrating that the original order was ambiguous and caused
a lot of wasted effort.
  One of the central discoveries of AI has been that problems that look easy
are often very hard.  Proving this rigorously is a powerful tool: it provides
the excuse that almost any interesting problem is too hard to solve.  So of
course we're late with the report.

Theoretical Issues
  Not all the work here has focused on immediate payoffs.  We
have studied several theoretical issues involved with excuses.  We've found
that all problems can be partitioned into:
   1) Already Solved Problems for which excuses are not needed.
   2) Unsolved Problems
   3) Somebody Else's Problem
  We concentrate on (2).  We've shown that this class is further dividable.
Of particular interest is the class of unsolved problems for which the set of
palatable excuses is infinite.  These problems never need to actually be
solved.  We can generate research proposals, programs and funds requests
indefinitely without ever having to produce any results.  We just compute the
next excuse in the series and go on.

Remaining problems
  It is easiest to generate excuses when the person receiving the excuse is
either a complete moron or really couldn't care less about the whole project.
Fortunately, this is often the case and can be the default assumption.  But is
often useful to model the receiver of the excuse.  We can than calulate
just how big a whopper he's likely to swallow.
  It is, of course, not necessary that the receiver believe the excuse, just
that he accepts it.  The system is not ready yet able to model why anyone
would accept the excuse "Honestly, we're just friends, there's nothing
between us at all."  But our research shows that most people accept this
excuse, and almost no one believes it.

  The system still has problems understanding different points of view.  For
instance, it cannot differentiate why

  "My neighbors were up drinking and fighting and doing drugs and screaming
all night, so I didn't get any sleep at all,"

 is a reasonable excuse for being late to work, but

  "I was up drinking and fighting and doing drugs and screaming all night, so
I didn't get any sleep at all," is not.

  Finally, the machine is handicapped by its looks.  No matter how
brilliantly it calculates a good excuse, it can't sweep back a head of
chestnut hair, fix a winning smile on its face, and say with heartfelt warmth,
"Oh, thank you SO much for understanding..."  And that is so much of the soul
of a truly good excuse.

------------------------------
                                                                                                                        