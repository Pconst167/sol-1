What Is Virtual Reality? A Homebrew Introduction
March 1993
Jerry Isdale, i.e. Isdale Engineering
email: 72330.770@compuserve.com (preferred)
(alternate email: isdale@well.sf.ca.us)

  This article is intended as a rough introduction to Virtual Reality (VR), 
primarily as background for (home-brew) development efforts (like the 
Group 3 effort). It is not meant to be The Definitive Treatise on VR. The 
reader is encouraged to search out other introductions and form your 
own opinions.  Contact Information and other sources of information are 
listed at the end of this paper.

   An excellent short treatment of the state of the art and a taxonomy of 
VR is given in the ACM Siggraph publication "Computer Graphics", Vol. 
26, #3, August 1992. It is a report on the US Government's National 
Science Foundation invitational workshop on Interactive Systems 
Program held March 23-24, 1992.  The purpose of the workshop was to 
identify and recommend future research directions in the area of virtual 
environments.  A longer exposition of that taxonomy can be found in the 
MIT Journal "Presence" Vol. 1 #2.

Contents:
1.	What is Virtual Reality
2.	Types of VR Systems
2.1.	Window on World Systems (WoW)
2.2.	Video Mapping
2.3.	Immersive Systems
2.4.	Telepresence
2.5.	Mixed Reality
3.	VR Hardware
3.1.	Manipulation and Control Devices
3.2.	Position Tracking
3.3.	Stereo Vision
4.	Levels of VR Systems
4.1.	Entry VR (EVR)
4.2.	Basic VR (BVR)
4.3.	Advanced VR (AVR)
4.4.	Immersion VR (IVR)
4.5.	Big Time VR
4.6.	SIMNET, Defense Simulation Internet
5.	Aspects of A VR Program
5.1.	Input Processes
5.2.	Simulation Process
5.3.	Rendering Processes
5.3.1.	Visual Renderer
5.3.2.	Auditory Rendering
5.3.3.	Haptic Rendering
5.3.4.	Other Senses
6.	World Space
6.1.	World Coordinates
6.2.	A World Divided: Separation of Environments
7.	World Database
7.1.	Storage Methods
7.2.	Objects
7.2.1. Position/Orientable
7.2.2. Hierarchy
7.2.3. Bounding Volume
7.3. Object Geometry
7.3.1.	3D PolyLines & PolyPoints
7.3.2.	Polygons
7.3.2.1. Vertex Join Set Polygon Format
7.3.3.	Primitives
7.3.4.	Solid Modeling & Boolean Operations
7.3.5.	Curves & Patches
7.3.6.	Dynamic Geometry (aka morphing)
7.3.7.	Swept Objects & Surface of Revolution
7.3.8.	Texture Maps & Billboard Objects
7.4.	Lights
7.5.	Cameras
7.6.	Scripts
7.6.1. Motion Scripts
7.6.2.	Physical or Procedural Modeling and Simulation
7.6.3.	Simple Animation
7.6.4. Trigger Scripts
7.6.5.	Connection Scripts
7.7.	Interaction Feedback
7.8.	Graphical User Interface/Control Panels
7.8.1.	Two  Dimensional Controls
7.8.2.	Three Dimensional Controls
7.9.	Hardware Control & Connections
7.10.	Room/Stage/Area Descriptions
8.	World Authoring versus Playback
9.	For More VR Information
9.1.	On-line Services & BBS
9.2. Internet NewsGroups
9.3.	Internet FTP Sites
9.4.	Local User Groups, USA
9.5.	Local User Groups, Other Coutntries:
9.6.	VRASP
9.7.	Journals & Newsletters
9.8.	Professional Societies
9.9.	VR Reference Books
9.10.	Computer Graphics Books
9.11.	Related Books
9.12.	VR Research Labs & Academia
10.	Companies Involved with Virtual Reality

1.	What is Virtual Reality

  The term Virtual Reality (VR) is used by many different people and 
currently has many meanings. There are some people to whom VR is a 
specific collection of technologies, that is a Head Mounted Display, Glove 
Input Device and Audio. However, the general concept of the systems 
goes way beyond that. The best definition of Virtual Reality I have see to 
date comes from the book "The Silicon Mirage" (see section on VR Books): 

   "Virtual Reality is a way for humans to visualize, manipulate and 
interact with computers and extremely complex data" 

  The visualization part refers to the computer generating visual, auditory 
or other sensual inputs. The images are graphical renderings of a world 
within the computer. This world may be a CAD model, a scientific 
simulation, or a view into a database. The user can interact with the 
world and directly manipulate objects within the world. Some worlds are 
animated by other processes, perhaps physical simulations, or simple 
animation scripts.

  Some people object to the term "Virtual Reality", saying it is an 
oxymoron. Other terms that have been used are Synthetic Environments, 
Cyberspace, Artificial Reality, Simulator Technology, etc. VR is the most 
common and sexiest. It has caught the attention of the media.

  The applications being developed for VR run a wide spectrum, from 
games to building and business planning. Many applications are worlds 
that are very similar to our own, like CAD or architectural modeling. 
Some applications provide ways of viewing from an advantageous 
perspective not possible with the real world, like scientific simulators and 
telepresense systems, air traffic control systems. Other applications are 
much different from anything we have ever directly experienced before. 
These latter applications may be the hardest, and most interesting 
systems. Visualizing the ebb and flow of the world's financial markets. 
Navigating a large corporate information base, etc.

2.	Types of VR Systems

  A major distinction of VR systems is the mode with which they interface 
to the user. There are some non-technologically mediated methods that 
some people stretch to include in VR, such as books, plays, movies or 
pure imagination. The above mentioned taxonomy can include these, but 
we wish to restrict VR to technology mediated systems.

2.1.	Window on World Systems (WoW)

  Some systems use a conventional computer monitor to display the 
visual world. This sometimes called desktop VR or  a Window on a World 
(WoW).  This concept traces its lineage back through the entire history of 
computer graphics. In 1965, Ivan Sutherland laid out a research 
program for computer graphics in a paper called "The Ultimate Display" 
that has driven the field for the past nearly thirty years. 

  One must look at a display screen, he said, as a window through which 
one beholds a virtual world. The challenge to computer graphics is to 
make the picture in the window look real, sound real and the objects act 
real. [quoted from Computer Graphics V26#3]

2.2.	Video Mapping

  A variation of the WoW approach merges a video input of the user's 
silhouette with a 2D computer graphic. The user watches a monitor that 
shows his body's interaction with the world. Myron Kruger has been a 
champion of this form of VR since the late 60's. He has published two 
books on the subject: "Artificial Reality" and "Artificial Reality II". At least 
one commercial system uses this approach, the Mandala system. This 
system is based on a Commodore Amiga with some added hardware and 
software. A version of the Mandala is used by the cable TV channel 
Nickelodeon for a game show (Nick Arcade) to put the contestants into 
what appears to be a large video game.

2.3.	Immersive Systems 

  The ultimate VR systems completely immerse the user's personal 
viewpoint inside the virtual world. These "immersive" VR systems are 
often equipped with a Head Mounted Display. This is a helmet or a face 
mask that holds the visual and auditory displays. The helmet may be free 
ranging, or it might be attached to some sort of a boom armature. 

  A nice variation of the immersive systems use multiple large projection 
displays to create a 'Cave'. An early implementation was called "The 
Closet Cathedral" for the ability to create the impression of an immense 
environment. within a small physical space. The Holodeck used in the 
television series "Star Trek: The Next Generation" is an extrapolation of 
this technology.

2.4.	Telepresence

  A variation on visualizing complete computer generated worlds is 
"Telepresence". This is a technology that links remote sensors in the real 
world with the senses of a human operator. The remote sensors might be 
located on a robot, or they might be on the ends of WALDO like tools. 
Fire fighters use remotely operated vehicles to handle some dangerous 
conditions. Surgeons are using very small instruments on cables to do 
surgery without cutting a major hole in their patients. The instruments 
have a small video camera at the business end. 

2.5.	Mixed Reality

  Merging the Telepresence and Virtual Reality systems gives the Mixed 
Reality or Seamless Simulation systems. Here the computer generated 
inputs are merged with telepresence inputs and the users view of the real 
world. A surgeon's view of a brain surgery is overlaid with images from 
earlier CAT scans and real-time ultrasound. A fighter pilot sees computer 
generated maps and data displays inside his fancy helmet visor. 

3.	VR Hardware

  There are a number of specialized types of hardware that have been 
developed or used for Virtual Reality applications.

3.1.	Manipulation and Control Devices

  One key element for interaction with a virtual world, is a means of 
tracking the position of a real world object, such as a head or hand. 
There are numerous methods for position tracking and control. Ideally a 
technology should provide 3 measures for position(X, Y, Z) and 3 
measures of orientation (roll, pitch, yaw). One of the biggest problem for 
position tracking is latency, or the time required to make the 
measurements and preprocess them before input to the simulation 
engine.

  The simplest control hardware is a conventional mouse, trackball or 
joystick. While these are two dimensional devices, creative programming 
can use them for 6D controls. There are a number of 3 and 6 
dimensional mice/trackball/joystick devices being introduced to the 
market at this time. These add some extra buttons and wheels that are 
used to control not just the XY translation of a cursor, but its Z 
dimension and rotations in all three directions. One 6D Joystick has 
recently become available, the Global Devices 6D Controller. It has a 
tennis ball mounted on a stick. You can pull and twist the ball in 
addition to the left/right & forward/back of a normal joystick.

  One common VR device is the instrumented glove.(NOTE: the use of a 
glove to manipulate objects in a computer is covered by a basic patent.) 
Here a glove is outfitted with sensors on the fingers as well as an overall 
position/orientation tracker. There are a number of different types of 
sensors that can be used. VPL (holders of the patent) made several 
DataGloves, mostly using fiberoptic sensors for finger bends and 
magnetic trackers for overal position. Mattel manufactured the 
PowerGlove for use with the Nintendo game system, for a short time.  
This device is easily adapted to interface to a personal computer. It 
provides some limited hand location and finger position data using strain 
gauges for finger bends and ultrasonic position sensors. The gloves are 
getting rare, but some can still be found at Toys R' Us and other discount 
stores.  Anthony Clifton recently posted this suggestion for a" very good 
resource for powergloves etc:  small children. A friend's son had gotten a 
glove a couple years ago and almost NEVER used it, so I bought it off the 
kid.  Remember children like money more than toys they never use."

3.2.	Position Tracking

  Mechanical armatures can be used to provide fast and very accurate 
tracking. Such armatures may look like a desk lamp (for basic 
position/orientation) or they may be highly complex exoskeletons (for 
more detailed positions). The drawbacks of mechanical sensors are the 
encumbrance of the device and its restrictions on motion.

  Ultrasonic sensors can be used to track position and orientation. A set 
of  emitters and receivers are used with a known relationship between 
the emitters and between the receivers. The emitters are pulsed in 
sequence and the time lag to each receiver is measured. Triangulation 
gives the position. Drawbacks to ultrasonics are low resolution, long lag 
times and susceptibility to echoes from the environment.

  Magnetic trackers use sets of coils that are pulsed to produce magnetic 
fields. The magnetic sensors determine the strength and angles of the 
fields. Limitations of these trackers are a high latency for the 
measurement and processing, range limitations, and interference from 
ferrous materials within the fields. However, magnetic trackers seem to 
be one of the preferred methods.

  Optical position tracking systems have been developed. One method 
uses a ceiling grid LEDs and a head mounted camera. The LEDs are 
pulsed in sequence and the cameras image is processed to detect the 
flashes. Two problems with this method are limited space (grid size) and 
lack of full motion (rotations). Another optical method uses a number of 
video cameras to capture simultaneous images that are correlated by 
high speed computers to track objects. Processing time (and cost of fast 
computers) is a major limiting factor here.

  Inertial trackers have been developed that are small and accurate 
enough for VR use. However, these devices generally only provide 
rotational measurements. They are also not accurate for slow position 
changes.

3.3.	Stereo Vision

  Stereo vision is often included in a VR system. This is accomplished by 
creating two different images of the world, one for each eye. The images 
are computed with the viewpoints offset by the equivalent distance 
between the eyes. There are a large number of technologies for presenting 
these two images. The images can be placed side-by-side and the viewer 
asked (or assisted) to cross their eyes.  The images can be projected 
through differently polarized filters, with corresponding filters placed in 
front of the eyes. Anaglyph images user red/blue glasses to provide a 
crude (no color) stereovision.

  The two images can be displayed sequentially on a conventional monitor 
or projection display. LCD shutter glasses are then used to shut off 
alternate eyes in synchronization with the display. When the brain 
receives the images in rapid enough succession, it fuses the images into 
a single scene and perceives depth. A fairly high display swapping rate 
(min 60hz) is required to avoid perceived flicker. A number of companies 
made low cost LCD shutter glasses for use with TVs (Sega, Nintendo, 
Toshiba, etc). There are circuits and code for hooking these up to a 
computer available on many of the Online systems, BBSs and Internet 
FTP sites mentioned later. However, locating the glasses themselves is 
getting difficult as none are still being made or sold for their original use.

  A more advanced stereoscopic system can be create by placing seperate 
small displays can be placed in front of each eye, with special optics to  
focus and stretch the perceived field of view. This setup is commonly 
known as a Head Mounted Display or HMD. Most lower cost HMDs 
($6000 range ) use LCD displays, while others use small CRTs. The more 
expensive HMDs use optical fibers to pipe the images from non-head 
mounted displays. ($60,000 and up) A HMD requires a position tracker 
in addition to the helmet. Alternatively, the binocular display can be 
mounted on an armature for support and tracking (a Boom display)

4.	Levels of VR Systems

  There are currently quite a number of different efforts to develop VR 
technology. Each of these projects has different goals and approach to 
the overall VR technology. Major (and Minor) University labs have big 
projects underway (UNC, Cornell, etc.). DARPA is investing heavily in VR 
and other simulation technologies. There are industry supported 
laboratories too, like the Human Interface Technologies Laboratory (HITL) 
in Seattle and Japanese NTT project. Many existing and startup 
companies are also building and selling world building tools (Autodesk, 
IBM's VUE, Sense8, VREAM).

  There is also a number of home-brew VR projects. Some of these are 
highly visible, being publicized either in conventional media (PCVR 
magazine) or in the electronic networks (Rend386, etc.). Others are 
individuals and small club projects.

4.1.	Entry VR (EVR)

   The 'Entry Level' VR system takes a stock personal computer or 
workstation and implements a WoW system. The system may be based 
on an IBM clone (MS-DOS/Windows) machine or an Apple Macintosh, or 
perhaps a Commodore Amiga. The DOS type machines (IBM PC clones) 
are the most prevalent. There are Mac based systems, but few very fast 
rendering ones and no public domain versions, to my knowledge.  
Whatever the base computer it includes a graphic display,  a 2D input 
device like a mouse, trackball or joystick,  the keyboard, hard disk & 
memory.

  Virtual Reality Studio (aka VR Studio, VRS) is a commercial example of 
an Entry Level VR product available from Accolade for PC and Amiga 
systems. VR Studio provides world creation and runtime versions of the 
program. Worlds created with the program can be freely distributed with 
the player package. There are a number of these worlds available from 
the networks. Compuserve's GraphDev forum has several in Library 11 
(VR Tech), like the company provided demo VRSDMO.ZIP (VRS.TXT gives 
a solution to the demo game). 

4.2.	Basic VR (BVR)

  The next step up from an EVR system adds some basic interaction and 
display enhancements.  Such enhancements would include a 
stereographic viewer (LCD Shutterglasses)  and a input/control device 
such as the Mattel PowerGlove and/or a multidimensional mouse or 
joystick. 

4.3.	Advanced VR (AVR)

  The next step up the VR technology ladder is to add a rendering 
accelerator and/or frame buffer and possibly other parallel processors for 
input handling, etc. The simplest enhancement in this area is a faster 
display card. For the PC class machines, there are a number of new fast 
VGA and SVGA accelerator cards. These can make a dramatic 
improvement in the rendering performance of a desktop VR system. 
Other more sophisticated image processors based on the Texas 
Instruments TI34020 or Intel i860 processor can make even more 
dramatic improvements in rendering capabilities. The i860 in particular 
is in many of the high end professional systems. The Silicon Graphics 
Reality Engine uses a number of i860 processors in addition to the usual 
SGI workstation hardware to achieve stunning levels of realism in real 
time animation.

  An AVR system might also add a sound card to provide mono, stereo or 
true 3D audio output. Some sound cards also provide voice recognition. 
This would be an excellent additional input device for VR applications. 

4.4.	Immersion VR (IVR)

  An Immersion VR system adds some type of immersive display system: 
a HMD, a Boom, or multiple large projection type displays. 

  An IVR system might also add some form of tactile, haptic and touch 
feedback interaction mechanisms. The area of Touch or Force Feedback 
(known collectively as Haptics) is a very new research arena.

4.5.	Big Time VR

  Many of the more advanced systems are being designed as software 
toolkits or operating systems for VR. This workbench approach allows 
them to substitute different input devices, renderers, simulation systems, 
etc. Some of these systems run as distributed processes over a network 
of computers. 

4.6.	SIMNET, Defense Simulation Internet

  One of the biggest VR projects is the Defense Simulation Internet. This 
project is a standardization being pushed by the USA Defense 
Department to enable diverse simulators to be interconnected into a vast 
network. It is an outgrowth of the DARPA (Defense Advanced Research 
Projects Administration) SIMNET project of the later 1980s. The basic 
Distributed Interactive Simulation (DIS) protocol has been defined by the 
Orlando Institute for Simulation & Training. It is the basis for the next 
generation of SIMNET, the Defense Simulation Internet (DSI). (love those 
acronyms!) A good, accessible treatment of SIMNET and DSI can be 
found in the premier issue of WIRED magazine (January 1993) entitled 
"War is Virtual Hell" by Bruce Sterling.

5.	Aspects of A VR Program

  Just what is required of a VR program? The basic parts of the system 
can be broken down into an Input Processor, a Simulation Processor, a 
Rendering Process, and a World Database. All these parts must consider 
the time required for processing. Every delay in response time degrades 
the feeling of 'presence' and reality of the simulation. 

5.1.	Input Processes

  The Input Processes of a VR program control the devices used to input 
information to the computer. There are a wide variety of possible input 
devices: keyboard, mouse, trackball, joystick, 3D & 6D position trackers 
(glove, wand, head tracker, body suit, etc.). A network system would add 
inputs from the net. A voice recognition system is also a good 
augmentation for VR, especially if the user's hands are being used for 
other tasks.

5.2.	Simulation Process

  The core of a VR program is the simulation system. This is the process 
that knows about the objects and the various inputs. It handles the 
interactions, the scripted object actions, simulations of physical laws 
(real or imaginary) and determines the world status. This simulation is 
basically a discrete process that is iterated once for each time step or 
frame. A networked VR application may have multiple simulations 
running on different machines, each with a different time step. 
Coordination of these can be a complex task.

5.3.	Rendering Processes

  The Rendering Processes of a VR program are those that create the 
sensations that are output to the user. A network VR program would also 
output data to other network processes. There would be separate 
rendering processes for visual, auditory, haptic (touch/force), and other 
sensory systems. Each renderer would take a description of the world 
state from the simulation process or derive it directly from the World 
Database for each time step.

5.3.1.	Visual Renderer

  The visual renderer is the most common process and it has a long 
history from the world of computer graphics and animation. The reader is 
encouraged to become familiar with various aspects of this technology.

  The major consideration of a graphic renderer for VR applications is the 
frame generation rate. It is necessary to create a new frame every 1/20 of 
a second or faster. (1/20 is roughly the minimum rate at which the 
human brain will merge a stream of still images and perceive a smooth 
animation. 1/24fps is the standard rate for film, 1/25fps is PAL TV, 1/30 
is NTSC TV rates. 1/60fps is Showscan film rate.) This requirement 
eliminates a number of rendering techniques such as raytracing and 
radiosity. These techniques can generate very realistic images but often 
take hours to generate single frames. Visual renderers for VR use other 
methods such as a 'painter's algorithm', a Z-Buffer, or other Scanline 
oriented algorithm. There are many areas of visual rendering that have 
been augmented with specialized hardware.

  The visual rendering process is often referred to as a rendering pipeline. 
This refers to the series of sub-processes that are invoked to create each 
frame. A sample rendering pipeline starts with a description of the world, 
the objects, lighting and camera (eye) location in world space. A first step 
would be eliminate all objects that are not visible by the camera. This can 
be quickly done by clipping the object bounding box or sphere against 
the viewing pyramid of the camera. Then the remaining objects have their 
geometry's transformed into the eye coordinate system (eye point at 
origin). Then the hidden surface algorithm and actual pixel rendering is 
done. 

  The pixel rendering is also known as the 'lighting' or 'shading' 
algorithm. There are a number of different methods that are possible 
depending on the realism and calculation speed available. The simplest 
method is called flat shading and simply fills the entire area with the 
same color. The next step up provides some variation in color across a 
single surface. Beyond that is the possibility of smooth shading across 
surface boundaries, adding highlights, reflections, etc.

  An effective short cut for visual rendering is the use of "texture" or 
"image" maps. These are pictures that are mapped onto objects in the 
virtual world. Instead of calculating lighting and shading for the object, 
the renderer determines which part of the texture map is visible at each 
visible point of the object. The resulting image appears to have 
significantly more detail than is otherwise possible. Some VR systems 
have special 'billboard' objects that always face towards the user. By 
mapping a series of different images onto the billboard, the user can get 
the appearance of moving around the object.

5.3.2.	Auditory Rendering

  A VR system is greatly enhanced by the inclusion of an audio 
component. This may produce mono, stereo or 3D audio. The latter is a 
fairly difficult proposition. It is not enough to do stereo-pan effects as the 
mind tends to locate these sounds inside the head. Research into 3D 
audio has shown that there are many aspects of our head and ear shape 
that effect the recognition of 3D sounds. It is possible to apply a rather 
complex mathematical function (called a Head Related Transfer Function 
or HRTF) to a sound to produce this effect. The HRTF is a very personal 
function that depends on the individual's ear shape, etc. However, there 
has been significant success in creating generalized HRTFs that work for 
most people and most audio placement. There remains a number of 
problems, such as the 'cone of confusion' wherein sounds behind the 
head are perceived to be in front of the head.

  Sound has also been suggested as a means to convey other information, 
such as surface roughness. Dragging your virtual hand over sand would 
sound different than dragging it through gravel.

5.3.3.	Haptic Rendering

  Haptics is the generation of touch and force feedback information. This 
area is a very new science and there is much to be learned. There have 
been very few studies done on the rendering of true touch sense (such as 
liquid, fur, etc.).  Almost all systems to date have focused on force 
feedback and kinesthetic senses. These systems can provide good clues 
to the body regarding the touch sense, but are considered distinct from 
it. Many of the haptic systems thus far have been exo-skeletons that can 
be used for position sensing as well as providing resistance to movement 
or active force application.

5.3.4.	Other Senses

  The sense of balance and motion can be served to a fair degree in a VR 
system by a motion platform. These are used in flight simulators and 
some theaters to provide some motion cues that the mind integrates with 
other cues to perceive motion. It is not necessary to recreate the entire 
motion perfectly to fool the mind into a willing suspension of disbelief.

  The sense of temperature has seen some technology developments. 
There exist very small electrical heat pumps that can produce the 
sensation of heat and cold in a localized area. These system are fairly 
expensive.

  Other senses such as taste, smell, pheromone, etc. are beyond our 
ability to render rapidly and effectively. Sometimes, we just don't know 
enough about the functioning of these other senses.

6.	World Space

  The virtual world itself needs to be defined in a 'world space'. By its 
nature as a computer simulation, this world is necessarily limited. The 
computer must put a numeric value on the locations of each point of 
each object within the world. Usually these 'coordinates' are expressed in 
Cartesian dimensions of X, Y, and Z (length, height, depth). It is possible 
to use alternative coordinate systems such as spherical but Cartesian 
coordinates are the norm for almost all applications. Conversions 
between coordinate systems are fairly simple (if time consuming).

6.1.	World Coordinates

  A major limitation on the world space is the type of numbers used for 
the coordinates. Some worlds use floating point coordinates. This allows 
a very large range of numbers to be specified, with some precision lost on 
large numbers. Other systems used fixed point coordinates, which 
provides uniform precision on a more limited range of values. The choice 
of fixed versus floating point is often based on speed as well as the desire 
for a uniform coordinate field.

6.2.	A World Divided: Separation of Environments

  One method of dealing with the limitations on the world coordinate 
space is to divide a virtual world up into multiple worlds and provide a 
means of transiting between the worlds.  This allows fewer objects to be 
computed both for scripts and for rendering. There should be multiple 
stages (aka rooms, areas, zones, worlds, multiverses, etc.) and a way to 
move between them. 

7.	World Database

  The storage of information on objects and the world is a major part of 
the design of a VR system. The primary things that are stored in the 
World Database (or World Description Files) are the objects that inhabit 
the world, scripts that describe actions of those objects or the user 
(things that happen to the user), lighting, program controls, and 
hardware device support.

7.1.	Storage Methods

  There are a number of different ways the world information may be 
stored: a single file, a collection of files, or a database. The multiple file 
method is one of the more common approaches for VR development 
packages. Each object has one or more files (geometry, scripts, etc.) and 
there is some overall 'world' file that causes the other files to be loaded. 
Some systems also include a configuration file that defines the hardware 
interface connections.

  Sometimes the entire database is loaded during program startup, other 
systems only read the currently needed files. A real database system 
helps tremendously with the latter approach. An Object Oriented 
Database would be a great fit for a VR system, but I am not aware of any 
projects currently using one.

  The data files are most often stored as ASCII (human readable) text 
files. However, in many systems these are replaced by binary computer 
files. Some systems have all the world information compiled directly into 
the application.

7.2.	Objects

  Objects in the virtual world can have geometry, hierarchy, scripts, and 
other attributes. The capabilities of objects has a tremendous impact on 
the structure and design of the system. In order to retain flexibility,  a list 
of named attribute/values pairs is often used. Thus attributes can be 
added to the system without requiring changes to the object data 
structures. 

  These attribute lists would be addressable by name (i.e. cube.mass => 
mass of the cube object). They may be a scalar, vector, or expression 
value. They may be addressable from within the scripts of their object. 
They might be accessible from scripts in other objects.

7.2.1. Position/Orientable

  An object is positionable and orientable. That is, it has a location and 
orientation in space.  Most objects can have these attributes modified by 
applying translation and rotation operations. These operations are often 
implemented using methods from vector and matrix algebra.

7.2.2. Hierarchy

  An object may be part of an object part HIERARCHY with a parent, 
sibling, and child objects. Such an object would inherit the 
transformations applied to it's parent object and pass these on to it's 
siblings and children. Hierarchies are used to create jointed figures such 
as robots and animals. They can also be used to  model other things like 
the sun, Êplanets and moons in a solar system.

7.2.3. Bounding Volume

  Additionally, an object  should include a BOUNDING VOLUME. The 
simplest bounding volume is the Bounding Sphere, specified by a center 
and radius. Another simple alternative is the Bounding Cube. This data 
can be used for rapid object culling during rendering and trigger 
analysis. Objects whose bounding volume is completely outside the 
viewing area need not be transformed or considered further during 
rendering. Collision detection with bounding spheres is very rapid. It 
could be used alone, or as a method for culling objects before more 
rigorous collision detection algorithms are applied.

7.3. Object Geometry

  The modeling of object shape and geometry is a large and diverse field. 
Some approaches seek to very carefully model the exact geometry of real 
world objects. Other methods seek to create simplified representations.  
Most VR systems sacrifice detail and exactness for simplicity for the sake 
of rendering speed.

  The simplest objects are single dimensional points. Next come the two 
dimensional vectors. Many CAD systems create and exchange data as 2D 
views. This information is not very useful for VR systems, except for 
display on a 2D surface within the virtual world. There are some 
programs that can reconstruct a 3D model of an object, given a number 
of 2D views.

7.3.1.	3D PolyLines & PolyPoints

  The simplest 3D objects are known as PolyPoints and PolyLines. A 
PolyPoint is simply a collection of points in space. A Polyline is a set of 
vectors that form a continuous line.

7.3.2.	Polygons

  The most common form of objects used in VR systems are based on flat  
polygons. A polygon is a planar, closed multi-sided figure. They maybe 
convex or concave, but some systems require convex polygons. The use 
of polygons often gives objects a faceted look. This can be offset by more 
advanced rendering techniques such as the use of smooth shading and 
texture mapping.

  Some systems use simple triangles or quadrilaterals instead of more 
general polygons. This can simplify the rendering process, as all surfaces 
have a known shape. However, it can also increase the number of 
surfaces that need to be rendered.

7.3.2.1. Vertex Join Set Polygon Format

  Vertex Join Set Polygon Format is a useful form of polygonal object. For 
each object in a VJS, there is a common pool of Points that are 
referenced by the polygons for that object. Transforming these shared 
points reduces the calculations needed to render the object. A point at 
the edge of a cube is only processed once, rather once for each of the 
three edge/polygons that reference it. The PLG format used by REND386 
is an example of a Vertex Join Set, as is the BYU format used by the 
'ancient' MOVIE.BYU program.)

  The geometry format can support precomputed polygon and vertex 
normals. Both Polygons and vertices should be allowed a color attribute. 
Different renderers may use or  ignore these and possibly more advanced 
surface characteristics. Precomputed polygon normals are very helpful 
for backface polygon removal.  Vertices may also have texture 
coordinates assigned to support texture or other image mapping 
techniques.

7.3.3.	Primitives

  Some systems provide only Primitive Objects, such as cubes, cones, and 
spheres. Sometimes, these objects can be slightly deformed by the 
modeling package to provide more interesting objects.

7.3.4.	Solid Modeling & Boolean Operations

  Solid Modeling (aka Computer Solid Geometry, CSG) is one form of 
geometric modeling that uses primitive objects. It extends the concept by 
allowing various addition, subtraction, Boolean and other operations 
between these primitives. This can be very useful in modeling objects 
when you are concerned with doing physical calculations, such as center 
of mass, etc. However, this method does incur some significant 
calculations and is not very useful for VR applications. It is possible to 
convert a CSG model into polygons. Various complexity polygonal models 
could be made from a single high resolution 'metaobject' of a CSG type.

7.3.5.	Curves & Patches

  Another advanced form of geometric modeling is the use of curves and 
curved surfaces (aka patches). These can be very effective in representing 
complex shapes, like the curved surface of an automobile, ship or beer 
bottle. However, there is significant calculation involved in determining 
the surface location at each pixel, thus curve based modeling is not used 
directly in VR systems. It is possible, however, to design an object using 
curves and then compute a polygonal representation of those curved 
patches.  Various complexity polygonal models could be made from a 
single high resolution 'metaobject'.

7.3.6.	Dynamic Geometry (aka morphing)

  It is sometimes desirable to have an object that can change shape. The 
shape might simply be deformed, such a bouncing ball or the 
squash/stretch used in classical animation ('toons'), or it might actually 
undergo metamorphosis into a completely different geometry. The latter 
effect is commonly known as 'morphing' and has been extensively used 
in films, commercials and television shows. Morphing can be done in the 
image domain (2D morph) or in the geometry domain (3D morph). The 
latter is applicable to VR systems. The simplest method of doing a 3D 
morph is to precompute the various geometry's and step through them 
as needed. A system with significant processing power can handle real 
time object morphing.

7.3.7.	Swept Objects & Surface of Revolution

  A common method for creating objects is known as Sweeping and 
Surfaces of Revolution. These methods use an outline or template curve 
and a backbone. The template is swept along the backbone creating the 
object surface (or rotated about a single axis to create a surface of 
revolution). This method may be used to create either curve surfaces or 
polygonal objects.  For VR applications, the sweeping would most likely 
be performed during the object modeling (creation) phase, and the 
resulting polygonal object stored for real time use. 

7.3.8.	Texture Maps & Billboard Objects

  As mentioned in the section on rendering, texture maps can be used to 
provide the appearance of more geometric complexity without the 
geometric calculations. Using flat polygonal objects that maintain an 
orientation towards the eye/camera (billboards) and multiple texture 
maps can extend this trick even further.

7.4.	Lights

  Lighting is a very important part of a virtual world (if it is visually 
rendered). Lights can be ambient (everywhere), or located. Located lights 
have position and may have orientation, color, intensity and a cone of 
illumination. The more complex the light source, the more computation 
is required to simulate its effect on objects.

7.5.	Cameras

  Cameras or viewpoints may be described in the World Database. 
Generally, each user has only one viewpoint at a time (ok, two closely 
spaced viewpoints for stereoscopic systems). However, it may be useful to 
define alternative cameras that can be used as needed. An example 
might be an overhead camera that shows a schematic map of the virtual 
world and the user's location within it (You Are Here.)

7.6.	Scripts

  A virtual world consisting only of static objects is only of mild interest. 
Many researchers and enthusiasts of VR have remarked that interaction 
is the key to a successful and interesting virtual world. This requires 
some means of defining the actions that objects take on their own and 
when the user (or other objects) interact with them. This i refer to 
generically as the World Scripting. I divide the scripts into three basic 
types: Motion Scripts, Trigger Scripts and Connection Scripts

  Scripts may be textual or they might be actually compiled into the 
program structure. The use of visual programming languages for world 
design was pioneered by VPL Research with their Body Electric system. 
This Macintosh based language used 2d blocks on the screen to 
represent inputs, objects and functions. The programmer would connect 
the boxes to indicate data flow.

7.6.1. Motion Scripts

  Motion scripts modify the position, orientation or other attributes of an 
object, light or camera based on the current system tick.  A 'tick' is one 
advancement of the simulation clock. Generally, this is equivalent to a 
single frame of visual animation. (VR generally uses Discrete Simulation 
methods)

  For simplicity and speed, only one motion script should be active for an 
object at any one instant.   Motion scripting is a potentially powerful 
feature, depending on how complex we allow these scripts to become.  
Care must be exercised since the interpretation of these scripts will 
require time, which impacts the frame and delay rates.

  Additionally, a script might be used to attach or detach an object from a 
hierarchy. For example, a script might attach the user to a CAR object 
when he wishes to drive around the virtual world. Alternatively, the user 
might 'pick up' or attach an object to himself.

7.6.2.	Physical or Procedural Modeling and Simulation

  A complex simulation could be used that models the interactions of the 
real physical world. This is sometimes referred to as Procedural 
Modeling. It can be a very complex and time consuming application. The 
mathematics required to solve the physical interaction equations can 
also be fairly complex. However, this method can provide a very realistic 
interaction mechanism.

7.6.3.	Simple Animation

  A simpler method of animation is to use simple formulas for the motion 
of objects.  A very simple example would be "Rotate about Z axis once 
every 4 seconds". This might also be represented as "Rotate about Z 10 
radians each frame".

  A slightly more advanced method of animation is to provide a 'path' for 
the object with controls on its speed at various points. These controls are 
sometimes referred to as "slow in-out". They provide a much more 
realistic motion than simple linear motion.

  If the motion is fixed, some systems can precompute the motion and 
provide a 'channel' of data that is evaluated at each time instance. This 
may be a simple lookup table with exact values for each frame, or it may 
require some sort of simple interpolation.

7.6.4. Trigger Scripts

  Trigger Scripts are invoked when some trigger event occurs, such as 
collision, proximity or selection.  The VR system needs to evaluate the 
trigger parameters at each TICK. For proximity detectors, this may be a 
simple distance check from the object to the 3D eye or effector object 
(aka virtual human) Collision detection is a more involved process. It is 
desirable but may not be practical without off loading the rendering and 
some UI tasks from the main processor.

7.6.5.	Connection Scripts

  Connection scripts control the connection of input and output devices 
to various objects. For example a connection script may be used to 
connect a glove device to a virtual hand object. The glove movements and 
position information is used to control the position and actions of the 
hand object in the virtual world. Some systems build this function 
directly into the program. Other systems are designed such that the VR 
program is almost entirely a connection script. 

7.7.	Interaction Feedback

  The user must be given some indication of interaction feedback when 
the virtual cursor selects or touches an object. Crude systems have only 
the visual feedback of seeing the cursor (virtual hand) penetrate an 
object. The user can then grasp or otherwise select the object. The 
selected object is then highlighted in some manner. Alternatively, an 
audio signal could be generated to indicate a collision. Some systems use 
simple touch feedback, such as a vibration in the joystick, to indicate 
collision, etc.

7.8.	Graphical User Interface/Control Panels

  A VR system often needs to have some sort of control panels available to 
the user. The world database may contain information on these panels 
and how they are integrated into the application. Alternatively, they may 
be a part of the program code.

  There are several ways to create these panels. There could be 2D menus 
that surround a WoW display, or are overlaid onto the image. An 
alternative is to place control devices inside the virtual world. The 
simulation system must then note user interaction with these devices as 
providing control over the world.

  One primary area of user control is control of the viewpoint (moving 
around within the virtual world). Some systems use the joystick or 
similar device to move. Others use gestures from a glove, such as 
pointing, to indicate a motion command.

  The user interface to the VW might be restricted to direct interaction in 
the  3D world. However, this is extremely limiting and requires lots of 3D 
calculations. Thus it is desirable to have some form of 2D Graphical user 
interface to assist in controlling the virtual world. These 'control panels' 
of the would appear to occlude portions of the 3D world, or perhaps the 
3D world would appear as a window or viewport set in a 2D screen 
interface. The 2D interactions could also be represented as a flat panel 
floating in 3D space, with a 3D effector controlling them.

7.8.1.	Two  Dimensional Controls

  There are four primary types of 2D controls and displays. (controls 
cause changes in the virtual world, displays show some measurement on 
the VW.) Buttons, Sliders, Gauges and Text. Buttons may be menu items 
with either icons or text identifiers. Sliders are used for more analog 
control over various attributes. A variation of a slider is the dial, but 
these are harder to implement as 2D controls. Gauges are graphical 
depiction's of the value of some attribute(s) of the world. Text may be 
used for both control and display. The user might enter text commands 
to some command parser. The system may use text displays to show the 
various attributes of the virtual world. 

  An additional type of 2D display might be a map or locator display. This 
would provide a point of reference for navigating the virtual world.

  The VR system needs a definition for how the 2D cursor effects these 
areas. It may be desirable to have a notion of a 'current control' that is 
the focus of the activity (button pressed, etc.) for the 2D effector. Perhaps 
the arrow keys on the keyboard could be used to change the current 
control, instead of using the mouse (which might be part of the 3D 
effector at present). 

7.8.2.	Three Dimensional Controls

  Some systems place the controls inside the virtual world. These are 
often implemented as a floating control panel object. This panel contains 
the usual 2D buttons, gauges, menu items, etc. perhaps with a 3D 
representation and interaction style. 

  There have also been some published articles on 3D control Widgets. 
These are interaction methods for directly controlling the 3D objects. One 
method implemented at Brown University attaches control handles to the 
objects. These handles can be grasped, moved, twisted, etc. to cause 
various effects on an object. For example, twisting one handle might 
rotate the object, while a 'rack' widget would provide a number of 
handles that can be used to deform the object by twisting its geometry.

7.9.	Hardware Control & Connections

  The world database may contain information on the hardware controls 
and how they are integrated into the application. Alternatively, they may 
be a part of the program code. Some VR systems put this information 
into a configuration file. I consider this extra file simply another part of 
the world database.

  The hardware mapping section would define the input/output ports, 
data speeds, and other parameters for each device. It would also provide 
for the logical connection of that device to some part of the virtual world. 
For example a position tracker might be associated with the viewer's 
head or hand.

7.10.	Room/Stage/Area Descriptions

  If the system supports the division of the virtual world into different 
areas, the world database  would need multiple scene descriptions. Each 
area description would give the names of objects in scene, stage 
description (i.e. size, backgrounds, lighting, etc.). There would also be 
some method of moving between the worlds, such as entering a doorway, 
etc., that would most likely be expressed in object scripts.

8.	World Authoring versus Playback

  A virtual world can be created, modified and experienced. Some VR 
systems may not distinguish between the creation and experiencing 
aspects. However, there is currently a much larger body of experience to 
draw upon for designing the world from the outside. This method may 
use techniques borrowed from architectural and other forms of Computer 
Aided Design (CAD) systems. Also the current technologies for immersive 
VR systems are fairly limiting in resolution, latency, etc. They are not 
nearly as well developed as those for more conventional computer 
graphics and interfaces.

  For many VR systems, it makes a great deal of sense to have a 
Authoring mode and a Playback mode. The authoring mode may be a 
standard text editor and compiler system, or it may include 3D graphic 
and other tools. The development project I am most involved with 
(CompuServe's Group 3) uses the split system and calls them the World 
Editor and World Player.

  An immersive authoring ability may also be desirable for some 
applications and some users. For example, an architect might have the 
ability to move walls, etc. when immersed, while the clients with him, 
who are not as familiar with the system, are limited to player status. That 
way they can't accidentally rearrange the house by leaning on a wall.

9.	For More VR Information

  The following information is provided to point the interested reader to 
more information on virtual reality. It is not a complete listing of all 
sources. I would appreciate hearing about other books, groups, on-line 
services, etc. for inclusion in future versions of this (and other) 
documents.

9.1.	On-line Services & BBS

  There are many computer bulletin boards and on-line services that 
support VR discussion and development. I am personally involved on 
several. My email address is given at the beginning of this paper. 

  I mostly use the CompuServe GraphDev Forum (Go GRAPHDEV). This 
forum has two message sections and two file libraries dedicate to VR (i.e. 
VR Concepts and VR Tech). It is the home for the Group 3 VR 
development project, of which I am the Project Leader. The libraries 
contain a number of VR programs, demos, concept papers, and an echo 
of the sci.virtual-worlds news group.  For information on CompuServe, 
call (800)848-8990 or (614) 457-8650

  The WELL (Whole Earth 'Lectronic Link) has a VR discussion area (GO 
VR).  For information on joining The WELL, call(415) 332-4335 or modem 
(415)332-6106. You can also telnet into the well as 'well.sf.ca.us' and 
sign on as newuser.

  The Byte Information Exchange (BIX) has a conference on VR: join 
virtual.world. To join BIX, call 1-800-695-4882 (2400 Baud, No Parity, 8 
data, 1 stop bit)

  America On-line reportedly also has a VR section. "VIRTUS" - virtual 
reality conference hosted by Virtues Corp. (info on joining AOL??)

  GENIE has an echo of sci.virtual-worlds. Contact Joel Anderson 
(joela@joela.apertus.com, GEnie: J.ANDERSON71) or Randall Severy - 
(GEnie: RSEVERY, CompuServe: 76166,3477,  Internet: 
ge!severy@uunet.uu.net) (Info on joining GENIE???)

  The Diaspar VR Network is a BBS dedicated to VR. David Mitchell is 
leading the VOID project which seeks to create low cost public access 
distributed VR applications. Dieaspar includes a number of 'VNET' or 
virtual BBS subsystems that are run by other individuals. Sense8 has 
one VNET on Diaspar that is used for their customer support. Diaspar 
can be reached at (714) 831-1776 (voice), 9600 Baud: 714-376-1234, 
1200 Baud: 714-376-1200. Diaspar is also  available from Internet sites 
via Telnet  as diaspar.com (192.215.11.1). On first login use the name 
"Diaspar"  (be sure to use capital D and lowercase iaspar.) This gets you 
to the BBS login area and you can get set up with your username and 
password. 

  The AMULET BBS (Santa Monica, CA).  Data access: (310)453-7705.  

  The CyberBBS (San Francisco, Bay Area CA), (510)527-9012

  One that I have heard of but not successfully connected to is 
SENSE/NET (801) 364-6227 (Salt Lake City, Utah)

9.2. Internet NewsGroups

  The Internet has newsgroups that are also known as the Usenet News. 
Some sysetms provide usenet readers that keep all usenet news in one 
place. Others require that you subscribe to those you wish to read and 
the news will be delivered as email. Subscribing requires sending an 
email message to either an individual or an automated list-server service. 
The list-servers take read the body of the message for special commands. 
The one you want is "subscibe <listname> <your full name>". Replacing 
<listname> with the name of the newslist you want and <your full name>  
with  your *real* name, not your login name.

Sci.virutal-worlds (aka: virtu-l): send a mail message to 
     listserv@uiucvmd.bitnet 
  with a body of
   subscribe virtu-l <full_name>
  Moderator: gbnewby@alexia.lis.uiuc.edu.(Greg Newby)
  Note: this list is also available in 'digest' form. This method combines a 
full day's messages into one message. To change to the digest form, send 
a message to the above list server with a body of:
   set virtu-l digest

Sci.virtual-worlds.apps (aka: vrapp-l)
     listserv@uiucvmd.bitnet
  with a body of
   subscribe vrapp-l <full_name>

Glove-list:  Subscribe by sending an email message to
       listserv@win30.nas.nasa.gov
  with a body of
      subscribe glove-list <your full name, not login id>
  Post to: glove-list@win30.nas.nasa.gov
   Moderator: jet@win30.nas.nasa.gov

Head-Trackers mailing list:  Subscribe by sending e-mail to
      trackers-request@qucis.queensu.ca
  with an informal request (not handled by automated system)
  post to: trackers@qucis.queensu.ca

REND386 users list: Subscribe by sending an email message to
       rend386-request@sunee.uwaterloo.ca
  with a body of
    subscribe your full name
  Post to: rend386@sunee.uwaterloo.ca
  Moderated by the creators of REND386 - Dave Stampe and Bernie Roehl

9.3.	Internet FTP Sites

milton.uwashingon.edu (128.95.136.1) (home of Sci.Virtual-Worlds 
Frequently Asked Questions, which is badly out of date as of 3/93)
ftp.u.washington.edu

sunee.uwaterloo.ca (129.97.50.50) (home of REND386 (freeware VR 
library/package)

karazm.math.uh.edu (129.7.128.1) (purported to be home of the power 
glove list, but archives here are real old)

ftp.apple.com (130.43.2.3) (sites list, Macintosh VR, CAD projects info)

src.doc.ic.ac.uk (146.169.2.1) (usenet archive /usenet...)

taurus.cs.nps.navy.mil: (Info on DIS and NPSNET, including C library)

avalon.chinalake.navy.mil (129.131.31.11) (lots of geometry files)

wuarchive.wustl.edu (128.252.135.4) mirror of milton VR, usenet archive

sunsite.unc.edu (152.2.22.81)  /pub/academic/computer-
science/virtual-reality (virtual reality demos, iris info, glasses, mirrors 
some of  milton.u.washington.edu, uforce info )

9.4.	Local User Groups, USA

  There are a lot of VR local user groups and 'Special Interest Groups'  
(SIGs) popping up around the world. Some samples are:

  Los Angeles VRSIG: contact Virtual Ventures/Dave Blackburn, 1300 
The Strand, Suite A,  Manhattan Beach, CA 90266  Voice:(310) 545-0369  
email: breeder@well.sf.ca.us  (I am a member of this group, which meets 
at the Electronic Cafe International  on 18th Street, Santa Monica, CA)

  Chicago VRSIG:  c/o Nina Adams, 3952 Western Ave, Western Springs, 
Chicago, IL 60558,  Voice: (708)246-0766  email: 
71052.1373@compuserve.com

  San Francisco VR Group, Contact Linda Jacobson, Verge (Virtual 
Reality Group), 16050 Kings Creek Rd.,  Boulder Creek, CA 95006;  
Voice: 415-826-4716. email:lindaj@well.sf.ca.us

  Houston TX: CyberSociety, 3336 Richmond Ave. #226, Houston, TX 
77098-3022, Voice: 713/520-5020, FAX:  713/520-7395, NETt: 
specdyn@well.sf.ca.us

  Stoughton WI: Andrew's VEE-AR Club,  c/o Andrew or Tom Hayward, 
624 Jackson Street, Stoughton, WI 53589

  Boston Computer Society VR Group, c/o Paul Matthews - Director, 
Building 1400,  One Kendal Square, Cambridge, MA 02139, Voice: 508 
921 6846  24hr,  Voice: 617 252 0600, email:pgm@world.std.com

  Louisville, Kentucky: VRSIG, c/o Andrew Prell, PO Box 43003, 
Louisville, KY 40253,  Voice:502 495-7186,  email: 
andrewp@well.sf.ca.us

9.5.	Local User Groups, Other Coutntries:

  Belgium: Genootschap voor Virtuele Realiteit  (Society for Virtual 
Reality), Philippe Van Nedervelde, Lichtaartsesteenweg 55, B-2275 
Poederlee - Lille, Belgium

  Canada: Univ. of Waterloo VR Group, c/o Rick Kazman (or c/o Bernie 
Roehl), Dept of Computer Science, Univ. of Waterloo, Waterloo, Ontario, 
N2L 3G1, Voice: (519) 888-4870 (R.Kazman), (519) 885-1211 x2607 
(B.Roehl), email: broehl@sunee.uwaterloo.ca

  Toronto Canada: Toronto VRSIG, c/o Caius Tenche, (416) 242-3119, 
email: caius.tenche@canrem.com

  England: VR User Group, Kim Baukham, 2 Beacon Road , London, 
SE13 6EH, England

  France:  Les Virtualistes, 90 Avenue de Paris, 92320 Chatillon, France, 
Voice: 1/47 35 65 48, FAX: 1/47 35 85 88

  Germany: Fraunhofer Institute for Computer Graphics & German 
Working Group on Virtual Reality (Related to Technical University in 
Darmstadt, and to the Computer Graphics Centre (ZGDV) in Darmstadt), 
Mr. Wolfgang Felger, Wilhelminenstr. 7,  W-6100 Darmstadt, F.R.G., 
Voice ++49-6151-155122, Fax.: ++49-6151-155199, email: 
felger@igd.fhg.de, email list: vr@igd.fhg.de

  South Africa VRSIG c/o Roger Layton, Chairman,  PO Box 72267, 
PARKVIEW, 2122,  South Africa, TEL: +27-11-788-5938, FAX: +27-11-
442-5529,  email: 74660.2154@compuserve.com

9.6.	VRASP

  A group that straddles the line between an on-line group, a local user 
group and a newsletter is the Virtual Reality Alliance for Students and 
Professionals (VRASP). This group is headquartered in New Jersey, but 
there are members around the world. Local collections of VRASP folks are 
known as 'Cells'. The group operates their own BBS and is active on 
many of the on-line services. They have an excellent newsletter, 
PixElation, that offers both technical articles and humorous reviews of 
various events. Subscriptions to PixElation is $30/yr, $20/yr for 
sustaining (active) members of VRASP. ($8/yr more for international) For 
more information contact:

  VRASP,  c/o Karin August, PO BOX 4139, Highland Park, NJ 08904-
4139,  email:71033.702@compuserve.com

9.7.	Journals & Newsletters

  PCVR Magazine. For the home-brew enthusiast. includes Code Disks, 
Editor: Joseph Gradecki, 1706 Sherman Hill Road, Unit A, Laramie, WY. 
82060,  VOICE/FAX: (307) 742-7675,  email: gradecki@rodeo.uwyo.edu,  
email: 70711.257@compuserve.com

  CyberEdge Journal. Excellent professional newsletter,  Ben Delaney, 
Editor, #1 Gate Six Road, Suite G,  Sausalito, CA 94965, Voice: 415 331-
EDGE (3343), FAX: 415 331-3643, email: 76217.3074@compuserve.com, 
email:bdel@well.sf.ca.us., ISSN# 1061-3099

  Presence: Teleoperators & Virtual Environments. Professional Tech 
Papers and Journal.,  MIT Press Journals, 55 Hayward St, Cambridge 
MA 02142, (800) 356-0343,  (617) 628-8569,  (617) 253-2889 (9-5 EST), 
Fax: (617) 258-6779,   email: hiscox@mitvma.mit.edu, ISSN 1054-7460

  Virtual Reality Report, Meckler Publishing, Sandra Helsel, Editor in 
Chief, Meckler Corporation,  11 Ferry Lane, Westport CT 06880, Voice: 
(203)226-6967

  VR Monitor: Frank Dunn, Editor,  Matrix Information Services, 18560 
Bungalow Drive, Lathrup Village, MI 48076, Voice: (313) 559-1526, 
email: matrix@well.sf.ca.us, email: 70117.2546@compuserve.com

  Virtural Reality News, Brian Lareau, Editor, Magellan Marketing Inc. 
32969 Hamilton Courts Suite 215, Farmington Hills Mich. 48334 313-
488-0330, email: larryv@msen,com

9.8.	Professional Societies

  There are two major professional computer associations that publish 
respected journals related to Virtual Reality.

  The Association for Computing Machinery (ACM) has a number of 
special interest groups whose journals and newsletters often have VR 
related articles. SIGGRAPH is the SIG for Computer Graphics. Their 
national convention is The Event for Computer Graphics each year.  The 
'93 conference will be in Anahiem CA, August 1-6. SIGCHI is the SIG for 
Computers and Human Interaction. This group has published a lot of 
research on new methods of interacting with computers, including a 
number of new VR applications. Contact info:

  Association for Computing Machinery,  1515 Broadway, 17th Floor,  
New York, NY 10036,   (212) 869-7440,  email: 
info.Membership@siggraph.org (for membership info),  email: 
info.Siggraph93@siggraph.org (for conference info)

  The Institute of Electrical and Electronics Engineers (IEEE) has a  
computer graphics SIG that publishes an execellent journal called "IEEE 
Computer Graphics and Applications".  Subscriptions are $26/year for 
society members, $47 for ACM or other society members, (six issues). 
(The Jan 1994 issue will have a concentration on Virtual Reality!) The 
IEEE also publishes a large number of books and conference 
proceedings. Contact info:

  IEEE Computer Society, PO Box 3014,  Los Alamitos, CA 90720-9804,   
(714) 821-8380,  (800) 272-6657 (Publication orders),  email: 
membership@compmail.com

9.9.	VR Reference Books

  There are a number of good reference works on VR and Computer 
Animation currently in print. There is also a whole slew of VR specific 
books due out in the Spring of '93. Most of these are aimed at the less 
technical reader, but some will include lots of good technical details. 
Many will include executable programs on disk, some with source code.

"Silicon Mirage: The Art and Science of Virtual Reality", Steve 
Aukstakalnis & David Blatner, Peach Pit Press 1992,ISBN 0-938151-82-
7

"Virtual Reality", Howard Rheingold, Summit Books, 1991, ISBN 0-671-
69363-8

"Virtual Reality Playhouse", Nicholas Lavroff, Waite Group Press, 1992 
ISBN 1-878739-19-0 (includes PC disk, apps are at most WoW 
interactive animations, but the only VR book+disk out right now)

"Cyberspace - First Steps", MIT Press, 1992 (collection of essays on VR), 
ISBN 0-262-52177-6

"Artificial Reality II", Myron Krueger, Addison-Wesley, 1991, ISBN: 0-201-
52260-8

"Computers as Theatre", Brenda Laurel, Addison-Wesley, 1991

"Virtual Reality: Theory, Practice, and Promise", Sandra Heisle & Judith 
Roth, Meckler Corp, 1990

"Virtual Reality: Through the New Looking Glass", Ken Pimentel & Kevin 
Teixeira, Intel/Windcrest/McGraw-Hill, 1993 ISBN 0-8306-4064-9
"Virtual Reality Creations", Dave Stampe Bernie Roehl & John Eagan, 
Waite Group Press, 1993 ISBN 1-878739-39-5 (Due out June/July '93, 
includes Rend386 on PC disk) 

"Adventures in Virtual Reality", Tom Hayward, Que Books, 1993, ISBN 1-
56529-208-1 (includes PC disk with VREAM world and other demos)

"International Directory of VR R&D", Meckler (to be published may 1993)

9.10.	Computer Graphics Books

"Computer Graphics (Principles and Applications)", Foley, Van Dam, 
Feiner & Hughes, 2nd Edition, Addison Wesley, 1990 ISBN 0-201-12110-
7 (This is The Bible of Computer Graphics. The classic text book.) 

"Visualization Graphics in C", Lee Adams, Windcrest/McGraw-Hill, 1991, 
ISBN 0-8306-3487-8

"Fundamentals of Three Dimensional Computer Graphics", Alan Watt, 
Addison Wesley, 1989, ISBN 0-201-15442-0

"New Trends in Animation and Visualization", Thalmann & Thalmann, 
John Wiley & Sons, 1991, ISBN 0-471-93020-2

"Physically-Based Modeling for Computer Graphics", Ronen Barzel, 
Academic Press, 1992, ISBN 0-12-079880-8

"MAKING THEM MOVE; Mechanics, Control and Animation of Articulated 
Figures", (Book and Video Package) Edited by Norman I. Badler (U 
Pennsylvania), Brian A. Barsky (U CalBerkeley) and David Zeltzer (Media 
Lab, MIT),Morgan Kaufmann Publishers, ISBN  Book/Video Package: 1-
55860-155-4  Book only: 1-55860-106-6 Tape only: 1-55860-154-6

9.11.	Related Books

  The following books, while not directly about VR technology, can 
provide some background ideas and concepts for VR.
ECCENTRIC SPACES, by Robert Harbison.  Boston:  David R. Godine, 
1988. $10.95, Subtitled, "A voyage through real and imagined worlds."

"The Design and Analysis of Spatial Data Structures", Haman Samet, 
Addison Wesley. 1990, ISBN: 0-201-50255-0

"Applications of Spatial data Structures", Hanan Samet, 1990, ISBN: 0-
201-50300-X

"The Visual Display of Quantitative Information", Edward Tufte, Graphic 
Press, 1983

"Envisioning Information", Edward Tufte, Graphic Press 1990

"Virtual Worlds, A Journey in Hype and Hyperreality", by Benjamin 
Woolley, published by Blackwell, Oxford, 1992. 

9.12.	VR Research Labs & Academia

(partially from the Milton.U.Washington.EDU FAQ area, which lists lots 
of schools. However, most of the postings there are from 1990 or 1991 
and I know some are no longer valid contact)

CAD Institute, 4100 E. Broadway, Suite 180, Phoenix, AZ 85040, (800) 
658-5744, Dean: John Morrison 76307.1552@compuserve.com

HITL (Human Interface Technology Laboratory), University of 
Washington, FJ-15, Seattle, WA 98195, (206) 543-5075, Director: Dr. 
Thomas A. Furness III

Visual Systems Laboratory, Institute for Simulation and Training 
Laboratory,  University of Central Florida, 12424 Research Parkway, 
Suite 300, Orlando, FL 32826,  Director: Dr. Michael Moshell

UNC Laboratory,  Univerisity of North Carolina, Chapel Hill,  Computer 
Science Department,  Chapel Hill, NC 27599-3175, Director: Fredrick 
Brooks

US Navy - Cyberview, David Sarnoff Research Center, Mark Long, 
CN5300,  Princeton NJ 08543-5300

Naval Postgraduate School,  Graphics and Video Lab,  Department of 
Computer Science,  Naval Postgraduate School,  Monterey, CA 93943-
5100,  Contacts: Dave Pratt, pratt@cs.nps.navy.mil,  Prof. Mike Zyda, 
zyda@trouble.cs.navy.mil

Computer Graphics Laboratory,  University of Alberta, Edmonton, 
Canada, Mark Green, Associate Professor (mark@cs.ualberta.ca)  (403) 
492-4584

National Center for Supercomputing Applications
  (NCSA) at the University of Illinois at Urbana-Champaign. Contact: 
Gregory B. Newby, Assistant Professor,  Graduate School of Library and 
Information Science. Room 417 DKH, 1407 W. Gregory Drive,  Urbana, 
IL, 61801.  gbnewby@alexia.lis.uiuc.edu

Networked Virtual Art Museum, Studio for Creative Inquiery, Carnigie 
Mellon University,  Pittsburgh PA  15213,  Carl Loeffler, (412) 268 3452, 
cel+@andrew.cmu.edu

10.	Companies Involved with Virtual Reality

  Companies involved with or producing VR products. The following is a 
composite of several lists i have found on Internet and CompuServe. It is 
by no way an exhaustive list.  There are commercial companies that sell 
such lists (and more info). Some of these are included in the list below.

1-900-VIRTUAL (yes a 1-900 number for VR) cost $1.25/minute

3D Imagetek , 4525-B San Fernando Rd., Glendale, CA 91204, Phone: 
(818) 507-1269   Fax: (818) 507-8537, Helmet Mounted Displays (HMDs)

3*DTV Corporation, P.O. Box Q, San Francisco, CA 94913-4316, Voice 
(415) 479-3516, Fax 415 479 3316 (LCD shutter glasses, other 
homebrew products)

Advanced Gravis Computer Technology Ltd. 7400 MacPherson Ave. #111,
Burnaby, B.C. V5J 5B6 Canada. 604-434-7274. MouseStick (optical 
joystick
for AT bus card) , 3D Sound Card.

Ascension Technology Corporation. P.O. Box 527, Burlington, VT 05402. 
802-
655-7879. Ascension Bird (6D magnetic tracker)

Autodesk, Inc. 2320 Marinship Way, Sausalito, CA 94965.  (800) 525-
2763 Cyberspace Developers Kit

CAE Electronics Ltd. C.P. 1800 Saint-Laurent, Quebec, H4L 4X4 
Canada. 514-341-6780. Head-mount displays.

CiS. 285 Littleton Rd., Ste. 3, Westford, MA 01886. 603-894-5999, 508 
692-2600 (fax). Geometry Ball Jr. (6D joystick).

Clarity, Nelson Lane,  Garrison, NY  10524, Phone: (914) 424-4071  Fax: 
(914) 424-3467,Auditory display products

Covox, Inc. 675 Conger Street,  Eugene, Oregon  97402, Phone: (503) 
342-1271 Fax: (503) 342-1283,  "Voicemaster Key System" - PC voice 
interface $150 and other sound related products

Crystal River Engineering. 12350 Wards Ferry Rd., Groveland, CA 95321. 
209-962-6382. Convolvotron (4 channel 3D audio card for PC).

Dimension International, Zephyr One Calleva Park, Aldermaston, 
Berkshire RG7 4QZ , Phone: 07 34 810 077  Fax: 816 940, "Superscape" 
PC-based VR, uses 34020 graphics card to speed things up. 

Dimension Technologies, Inc., 176 Anderson Avenue, Rochester, NY  
14607, vox: 716-442-7450, fax: 716-442-7589, DTI 100M, projection 
video stereoviewing system.

Division Ltd. Quarry Rd., Chipping Sodbury, Bristol B517 6AX England. 
44-0454-324527. 80860-based VR. "Vision VR" hi-end system with 
multiple 80860s. PC-based, lo-end system with one 80860 and one 
Sharp HSSP per eye.

Exos 8. Blanchard Road, Burlington, MA 01803. 617229-2075. Hand-
worn interface devices.

Fake Space Labs. 935 Hamilton Ave., Menlo Park, CA 94025. 415-688-
1940. BOOM (stereo viewer on articulated arm).

Focal Point Audio 1402 Pine Ave. Suite 127, Niagara Falls, NY 14301. 
415-963-9188. 3D audio boards for Mac and PC.

Global Devices, 6630 Arabian Circle, Granite Bay CA 95661, (915)791-
2558, fax:915-791-4358. 6D controller & navigator - joystick/ball 
devices.

Gyration, Inc. 12930 Saratoga Ave., Bldg. C, Saratoga, CA 95070. 408-
255-3016. GyroPoint (optically sensed gyroscopic sensors).

Haitex Resources, Inc., Charleston, South Carolina, 803-881-7518, 
Haitex X-Specs 3D for the Amiga line. (glasses should work with PC 
circuit)

Horizon Entertainment,  P.O. Box 14020, St. Louis MO 63178-4020, 
(800) ILLUSION (455-8746), Virtuality Entertainment Games

Leep Systems, 241 Crescent St., Waltham, MA 02154,, Phone: (617) 647-
1395   Fax: (617) 899-9602"Cyberface" HMDs, optics for HMDs.

Logitech Inc. 6505 Kaiser Drive, Fremont, CA 94555. 415-795-8500. (6D 
mouse and head tracker).

Media Magic, Phone: (415) 662-2426, P.O. Box 507 Nicasio, CA 94946, 
Superb catalog of books and videos on VR, Chaos, Fractals, etc.

Mira Imaging, Inc. , 2257 South 1100 East, Suite 1A,  Salt Lake City, 
Utah  84106, (800) 950-6472, Phone: (801) 466-4641   Fax: (801) 466-
4699"Hyperspace" - 3D digitizing and modeling software

Myron Krueger, Artificial Reality,  55 Edith, Vernon, CA 06066, Phone: 
(203) 871-1375,Custom-designed virtual world environments

Pasha Publication,  P.O. Box 9188,  Arlington, VA 22219, Voice 800-424-
2908, VIRTUAL REALITY HANDBOOK: Products, Services and Resources

The University of Pensylvania,Center for Technology Transfer, 3700 
Market St., Suite 300,  Philadelphia, PA  19104, Phone: (215) 898-9585   
Fax: (215) 898-9519, "Jack" - full body sensor positioning system

Polhelmus, Inc. 1 Hercules Drive, P.O. Box560, Colchester, VT 05446. 
802-655-3159. Polhemus (3Space 6D magnetic tracker).

Pop-Optix Labs. 241 Crescent Street, Waltham, MA 02154. 617-647-
1395. Specialized optics for headmount displays.

Reel-3D Enterprises, Inc, PO BOX 2368, Culver City CA 90231, (310) 
837-2368, Toshiba LCD Shutter glasses

Real World Graphics, Phone: 0992 554 442  Fax: 554 827, 5 Bluecoats 
Ave., Hertford SG14 1PB. 80860-based VR systems. "SuperReality" with 
multiple 80860s and texturing ASICs on VME cards. Lo-end "Reality PC" 
has a four-processor PC card with  stereo framebuffer. Specialising in 
flight simulation.

Reflection Technology, 230 Second Ave., Waltham, MA 02154, Phone: 
(617) 890-5905   Fax: (617) 890-5918, "Private Eye" LED-based 
monochrome HMD.

RPI Advanced Technology Group, POB 14607   San Francisco, CA  
94114, Phone: (415) 777-3226, "The Personal Simulator" and "HMSI" 
(Head Mounted Sensory Interface device)

Sense8 Corporation. 1001 Bridgeway, P.O. Box 477, Sausalito CA 94965. 
415-331-6318, 415-331-9148 (fax). VR software and systems (for PC, 
Sun & Silicon Graphics) .

SimGraphics Engineering Corp. 1137 Huntington Drive, South 
Pasadena, CA 91030. 213-255-0900. Systems configuration house/OEM 
VR equipment supplier.

Shooting Star Technology ,1921 Holdom Ave., Burnaby, BC, V5B 3W4, 
Phone: (604) 298-8574   Fax: (604) 298-8580,Mechanical position sensor 
(approx $1499) 

SophisTech Research,  6936 Seaborn Street,  Lakewood, CA 90713-2832,  
(310) 421-7295,  (800) 4VR SOURCE (orders only), Virtual Reality 
Sourcebook

Spaceball Technologies, Inc. 2063 Landings, Sunnyvale, CA 94043. 408-
745- 0330. Spaceball (6D joystick).
Spectrum Dynamics,  3336 Richmond Ave. #226,  Houston, TX 77098-
3022, Voice: 713/520-5020, Fax :  713/520-7395, email: 
specdyn@well.sf.ca.us, VR equipment distributers, VAR, etc

StereoGraphics. 21 71-H East Francisco Blvd., San Rafael, CA 94901. 
415- 459-4500. Stereoscopic displays & LCD Shutter Systems.

Straylight. 150 Mount Bethel Road, Warren, NJ 07050. 908-580-0086. 
VR authoring systems.

Subjective Technologies. 1106 Second Street, Suite 103, Encinitas, CA 
92024. 619-942-0928. Tools for controlling virtual environments.

TiNi Alloy Co. 1144 65th Street, Unit A, Oakland, CA 94608. 510-658-
3172. Tactile feedback systems.

Virtual Research 1313 Socorro Ave., Sunnyvale, CA 94089. 408-739-
7114. Flight Helmet (head mounted display).

Virtual Technologies. P.O. Box 5984, Stanford, CA 94309. 415-599-2331. 
Instrumented gloves and clothing.

Vision Research Graphics, 99 Madbury Road, Durham, NH  03824, vox: 
603-868-2270, fax: 603-868-1352, Resellers of Haitex LCD glasses w/PC 
driver & software

The Vivid Group. 317 Adelaide Street, W., Suite 302, Toronto, Ontario, 
M5V IP9 Canada. 416-340-9290. 416-348-98()9 (fax). Mandala (VR 
authoring systems).

VREAM. 256X N. Clark Street, #250, Chicago, 11. 60614. 3-12-477-0425 
VR authoring systems.

W.Industries, Phone: 0533 542 127     Fax: 548 222, 3 Oswin Rd., 
Brailsford Industrial Park, Leicester LE3 1HR, "Virtuality" arcade VR.

World Design Inc. 5348 1/2 Ballard Ave.  Seattle, WA  98107, Phone: 
(206) 782-8630, Robert Jacobson - VR consultants, Information 
Designers

Xtensory Inc. 140 Sunridge Drive, Scolls Valley, CA 95066. 408-439-
0600. Tactile feedback systems.

